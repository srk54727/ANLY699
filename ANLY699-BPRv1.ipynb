{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\abhin'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# path : store the current path to convert back to it later\n",
    "path = os.getcwd()\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import ceil\n",
    "from tqdm import trange\n",
    "from subprocess import call\n",
    "from itertools import islice\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from scipy.sparse import csr_matrix, dok_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data dimension: \n",
      " (93041, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>185074</td>\n",
       "      <td>Other Parts - Fixed</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>146195</td>\n",
       "      <td>Tango TX1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>184715</td>\n",
       "      <td>Ventis Pro 5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>154025</td>\n",
       "      <td>Filter</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>154025</td>\n",
       "      <td>Depot Repair</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id              item_id  rating\n",
       "0   185074  Other Parts - Fixed       1\n",
       "1   146195            Tango TX1       1\n",
       "2   184715         Ventis Pro 5       1\n",
       "3   154025               Filter       1\n",
       "4   154025         Depot Repair       1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing dataset\n",
    "df = pd.read_csv(\"Invoice_python_bpr_2items.csv\")\n",
    "print('data dimension: \\n', df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for creating matrix based on threshold\n",
    "def create_matrix(data, users_col, items_col, ratings_col, threshold = None):\n",
    "    if threshold is not None:\n",
    "        data = data[data[ratings_col] >= threshold]\n",
    "        data[ratings_col] = 1\n",
    "    \n",
    "    for col in (items_col, users_col, ratings_col):\n",
    "        data[col] = data[col].astype('category')\n",
    "\n",
    "    ratings = csr_matrix((data[ratings_col],\n",
    "                          (data[users_col].cat.codes, data[items_col].cat.codes)))\n",
    "    ratings.eliminate_zeros()\n",
    "    return ratings, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<15004x103 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 93041 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating matrix\n",
    "items_col = 'item_id'\n",
    "users_col = 'user_id'\n",
    "ratings_col = 'rating'\n",
    "threshold = 1\n",
    "X, df = create_matrix(df, users_col, items_col, ratings_col, threshold)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for creating test dataset\n",
    "def create_train_test(ratings, test_size = 0.2, seed = 1234):\n",
    "    assert test_size < 1.0 and test_size > 0.0\n",
    "    train = ratings.copy().todok()\n",
    "    test = dok_matrix(train.shape)\n",
    "    rstate = np.random.RandomState(seed)\n",
    "    for u in range(ratings.shape[0]):\n",
    "        split_index = ratings[u].indices\n",
    "        n_splits = ceil(test_size * split_index.shape[0])\n",
    "        test_index = rstate.choice(split_index, size = n_splits, replace = False)\n",
    "        test[u, test_index] = ratings[u, test_index]\n",
    "        train[u, test_index] = 0\n",
    "    train, test = train.tocsr(), test.tocsr()\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<15004x103 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 68107 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test = create_train_test(X, test_size = 0.2, seed = 1234)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BPR:\n",
    "\n",
    "    def __init__(self, learning_rate = 0.01, n_factors = 15, n_iters = 10, \n",
    "                 batch_size = 1000, reg = 0.01, seed = 1234, verbose = True):\n",
    "        self.reg = reg\n",
    "        self.seed = seed\n",
    "        self.verbose = verbose\n",
    "        self.n_iters = n_iters\n",
    "        self.n_factors = n_factors\n",
    "        self.batch_size = batch_size\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        # to avoid re-computation at predict\n",
    "        self._prediction = None\n",
    "        \n",
    "    def fit(self, ratings):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        ratings : scipy sparse csr_matrix, shape [n_users, n_items]\n",
    "            sparse matrix of user-item interactions\n",
    "        \"\"\"\n",
    "        indptr = ratings.indptr\n",
    "        indices = ratings.indices\n",
    "        n_users, n_items = ratings.shape\n",
    "        \n",
    "        # ensure batch size makes sense, since the algorithm involves\n",
    "        # for each step randomly sample a user, thus the batch size\n",
    "        # should be smaller than the total number of users or else\n",
    "        # we would be sampling the user with replacement\n",
    "        batch_size = self.batch_size\n",
    "        if n_users < batch_size:\n",
    "            batch_size = n_users\n",
    "            sys.stderr.write('WARNING: Batch size is greater than number of users,'\n",
    "                             'switching to a batch size of {}\\n'.format(n_users))\n",
    "\n",
    "        batch_iters = n_users // batch_size\n",
    "        \n",
    "        # initialize random weights\n",
    "        rstate = np.random.RandomState(self.seed)\n",
    "        self.user_factors = rstate.normal(size = (n_users, self.n_factors))\n",
    "        self.item_factors = rstate.normal(size = (n_items, self.n_factors))\n",
    "        \n",
    "        # progress bar for training iteration if verbose is turned on\n",
    "        loop = range(self.n_iters)\n",
    "        if self.verbose:\n",
    "            loop = trange(self.n_iters, desc = self.__class__.__name__)\n",
    "        \n",
    "        for _ in loop:\n",
    "            for _ in range(batch_iters):\n",
    "                sampled = self._sample(n_users, n_items, indices, indptr)\n",
    "                sampled_users, sampled_pos_items, sampled_neg_items = sampled\n",
    "                self._update(sampled_users, sampled_pos_items, sampled_neg_items)\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def _sample(self, n_users, n_items, indices, indptr):\n",
    "        \"\"\"sample batches of random triplets u, i, j\"\"\"\n",
    "        sampled_pos_items = np.zeros(self.batch_size, dtype = np.int)\n",
    "        sampled_neg_items = np.zeros(self.batch_size, dtype = np.int)\n",
    "        sampled_users = np.random.choice(\n",
    "            n_users, size = self.batch_size, replace = False)\n",
    "\n",
    "        for idx, user in enumerate(sampled_users):\n",
    "            pos_items = indices[indptr[user]:indptr[user + 1]]\n",
    "            pos_item = np.random.choice(pos_items)\n",
    "            neg_item = np.random.choice(n_items)\n",
    "            while neg_item in pos_items:\n",
    "                neg_item = np.random.choice(n_items)\n",
    "\n",
    "            sampled_pos_items[idx] = pos_item\n",
    "            sampled_neg_items[idx] = neg_item\n",
    "\n",
    "        return sampled_users, sampled_pos_items, sampled_neg_items\n",
    "                \n",
    "    def _update(self, u, i, j):\n",
    "        \"\"\"\n",
    "        update according to the bootstrapped user u, \n",
    "        positive item i and negative item j\n",
    "        \"\"\"\n",
    "        user_u = self.user_factors[u]\n",
    "        item_i = self.item_factors[i]\n",
    "        item_j = self.item_factors[j]\n",
    "        \n",
    "        # decompose the estimator, compute the difference between\n",
    "        # the score of the positive items and negative items; a\n",
    "        # naive implementation might look like the following:\n",
    "        # r_ui = np.diag(user_u.dot(item_i.T))\n",
    "        # r_uj = np.diag(user_u.dot(item_j.T))\n",
    "        # r_uij = r_ui - r_uj\n",
    "        \n",
    "        # however, we can do better, so\n",
    "        # for batch dot product, instead of doing the dot product\n",
    "        # then only extract the diagonal element (which is the value\n",
    "        # of that current batch), we perform a hadamard product, \n",
    "        # i.e. matrix element-wise product then do a sum along the column will\n",
    "        # be more efficient since it's less operations\n",
    "        # http://people.revoledu.com/kardi/tutorial/LinearAlgebra/HadamardProduct.html\n",
    "        # r_ui = np.sum(user_u * item_i, axis = 1)\n",
    "        #\n",
    "        # then we can achieve another speedup by doing the difference\n",
    "        # on the positive and negative item up front instead of computing\n",
    "        # r_ui and r_uj separately, these two idea will speed up the operations\n",
    "        # from 1:14 down to 0.36\n",
    "        r_uij = np.sum(user_u * (item_i - item_j), axis = 1)\n",
    "        sigmoid = np.exp(-r_uij) / (1.0 + np.exp(-r_uij))\n",
    "        \n",
    "        # repeat the 1 dimension sigmoid n_factors times so\n",
    "        # the dimension will match when doing the update\n",
    "        sigmoid_tiled = np.tile(sigmoid, (self.n_factors, 1)).T\n",
    "\n",
    "        # update using gradient descent\n",
    "        grad_u = sigmoid_tiled * (item_j - item_i) + self.reg * user_u\n",
    "        grad_i = sigmoid_tiled * -user_u + self.reg * item_i\n",
    "        grad_j = sigmoid_tiled * user_u + self.reg * item_j\n",
    "        self.user_factors[u] -= self.learning_rate * grad_u\n",
    "        self.item_factors[i] -= self.learning_rate * grad_i\n",
    "        self.item_factors[j] -= self.learning_rate * grad_j\n",
    "        return self\n",
    "\n",
    "    def predict(self):\n",
    "        \"\"\"\n",
    "        Obtain the predicted ratings for every users and items\n",
    "        by doing a dot product of the learnt user and item vectors.\n",
    "        The result will be cached to avoid re-computing it every time\n",
    "        we call predict, thus there will only be an overhead the first\n",
    "        time we call it. Note, ideally you probably don't need to compute\n",
    "        this as it returns a dense matrix and may take up huge amounts of\n",
    "        memory for large datasets\n",
    "        \"\"\"\n",
    "        if self._prediction is None:\n",
    "            self._prediction = self.user_factors.dot(self.item_factors.T)\n",
    "\n",
    "        return self._prediction\n",
    "\n",
    "    def _predict_user(self, user):\n",
    "        \"\"\"\n",
    "        returns the predicted ratings for the specified user,\n",
    "        this is mainly used in computing evaluation metric\n",
    "        \"\"\"\n",
    "        user_pred = self.user_factors[user].dot(self.item_factors.T)\n",
    "        return user_pred\n",
    "\n",
    "    def recommend(self, ratings, N = 5):\n",
    "        \"\"\"\n",
    "        Returns the top N ranked items for given user id,\n",
    "        excluding the ones that the user already liked\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        ratings : scipy sparse csr_matrix, shape [n_users, n_items]\n",
    "            sparse matrix of user-item interactions \n",
    "        \n",
    "        N : int, default 5\n",
    "            top-N similar items' N\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        recommendation : 2d ndarray, shape [number of users, N]\n",
    "            each row is the top-N ranked item for each query user\n",
    "        \"\"\"\n",
    "        n_users = ratings.shape[0]\n",
    "        recommendation = np.zeros((n_users, N), dtype = np.uint32)\n",
    "        for user in range(n_users):\n",
    "            top_n = self._recommend_user(ratings, user, N)\n",
    "            recommendation[user] = top_n\n",
    "\n",
    "        return recommendation\n",
    "\n",
    "    def _recommend_user(self, ratings, user, N):\n",
    "        \"\"\"the top-N ranked items for a given user\"\"\"\n",
    "        scores = self._predict_user(user)\n",
    "\n",
    "        # compute the top N items, removing the items that the user already liked\n",
    "        # from the result and ensure that we don't get out of bounds error when \n",
    "        # we ask for more recommendations than that are available\n",
    "        liked = set(ratings[user].indices)\n",
    "        count = N + len(liked)\n",
    "        if count < scores.shape[0]:\n",
    "\n",
    "            # when trying to obtain the top-N indices from the score,\n",
    "            # using argpartition to retrieve the top-N indices in \n",
    "            # unsorted order and then sort them will be faster than doing\n",
    "            # straight up argort on the entire score\n",
    "            # http://stackoverflow.com/questions/42184499/cannot-understand-numpy-argpartition-output\n",
    "            ids = np.argpartition(scores, -count)[-count:]\n",
    "            best_ids = np.argsort(scores[ids])[::-1]\n",
    "            best = ids[best_ids]\n",
    "        else:\n",
    "            best = np.argsort(scores)[::-1]\n",
    "\n",
    "        top_n = list(islice((rec for rec in best if rec not in liked), N))\n",
    "        return top_n\n",
    "    \n",
    "    def get_similar_items(self, N = 5, item_ids = None):\n",
    "        \"\"\"\n",
    "        return the top N similar items for itemid, where\n",
    "        cosine distance is used as the distance metric\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        N : int, default 5\n",
    "            top-N similar items' N\n",
    "            \n",
    "        item_ids : 1d iterator, e.g. list or numpy array, default None\n",
    "            the item ids that we wish to find the similar items\n",
    "            of, the default None will compute the similar items\n",
    "            for all the items\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        similar_items : 2d ndarray, shape [number of query item_ids, N]\n",
    "            each row is the top-N most similar item id for each\n",
    "            query item id\n",
    "        \"\"\"\n",
    "        # cosine distance is proportional to normalized euclidean distance,\n",
    "        # thus we normalize the item vectors and use euclidean metric so\n",
    "        # we can use the more efficient kd-tree for nearest neighbor search;\n",
    "        # also the item will always to nearest to itself, so we add 1 to \n",
    "        # get an additional nearest item and remove itself at the end\n",
    "        normed_factors = normalize(self.item_factors)\n",
    "        knn = NearestNeighbors(n_neighbors = N + 1, metric = 'euclidean')\n",
    "        knn.fit(normed_factors)\n",
    "\n",
    "        # returns a distance, index tuple,\n",
    "        # we don't actually need the distance\n",
    "        if item_ids is not None:\n",
    "            normed_factors = normed_factors[item_ids]\n",
    "\n",
    "        _, items = knn.kneighbors(normed_factors)\n",
    "        similar_items = items[:, 1:].astype(np.uint32)\n",
    "        return similar_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "BPR:   0%|          | 0/300 [00:00<?, ?it/s]\n",
      "BPR:   0%|          | 1/300 [00:00<00:59,  5.04it/s]\n",
      "BPR:   1%|          | 2/300 [00:00<01:00,  4.93it/s]\n",
      "BPR:   1%|          | 3/300 [00:00<00:59,  5.03it/s]\n",
      "BPR:   1%|▏         | 4/300 [00:00<00:57,  5.11it/s]\n",
      "BPR:   2%|▏         | 5/300 [00:00<00:57,  5.16it/s]\n",
      "BPR:   2%|▏         | 6/300 [00:01<00:56,  5.18it/s]\n",
      "BPR:   2%|▏         | 7/300 [00:01<00:56,  5.22it/s]\n",
      "BPR:   3%|▎         | 8/300 [00:01<00:55,  5.25it/s]\n",
      "BPR:   3%|▎         | 9/300 [00:01<00:55,  5.26it/s]\n",
      "BPR:   3%|▎         | 10/300 [00:01<00:54,  5.28it/s]\n",
      "BPR:   4%|▎         | 11/300 [00:02<00:54,  5.29it/s]\n",
      "BPR:   4%|▍         | 12/300 [00:02<00:54,  5.28it/s]\n",
      "BPR:   4%|▍         | 13/300 [00:02<00:54,  5.28it/s]\n",
      "BPR:   5%|▍         | 14/300 [00:02<00:54,  5.28it/s]\n",
      "BPR:   5%|▌         | 15/300 [00:02<00:53,  5.28it/s]\n",
      "BPR:   5%|▌         | 16/300 [00:03<00:53,  5.30it/s]\n",
      "BPR:   6%|▌         | 17/300 [00:03<00:53,  5.31it/s]\n",
      "BPR:   6%|▌         | 18/300 [00:03<00:53,  5.27it/s]\n",
      "BPR:   6%|▋         | 19/300 [00:03<00:53,  5.24it/s]\n",
      "BPR:   7%|▋         | 20/300 [00:03<00:53,  5.20it/s]\n",
      "BPR:   7%|▋         | 21/300 [00:04<00:53,  5.19it/s]\n",
      "BPR:   7%|▋         | 22/300 [00:04<00:53,  5.24it/s]\n",
      "BPR:   8%|▊         | 23/300 [00:04<00:52,  5.25it/s]\n",
      "BPR:   8%|▊         | 24/300 [00:04<00:52,  5.27it/s]\n",
      "BPR:   8%|▊         | 25/300 [00:04<00:51,  5.29it/s]\n",
      "BPR:   9%|▊         | 26/300 [00:04<00:51,  5.29it/s]\n",
      "BPR:   9%|▉         | 27/300 [00:05<00:51,  5.28it/s]\n",
      "BPR:   9%|▉         | 28/300 [00:05<00:51,  5.29it/s]\n",
      "BPR:  10%|▉         | 29/300 [00:05<00:51,  5.28it/s]\n",
      "BPR:  10%|█         | 30/300 [00:05<00:50,  5.29it/s]\n",
      "BPR:  10%|█         | 31/300 [00:05<00:50,  5.30it/s]\n",
      "BPR:  11%|█         | 32/300 [00:06<00:50,  5.29it/s]\n",
      "BPR:  11%|█         | 33/300 [00:06<00:50,  5.29it/s]\n",
      "BPR:  11%|█▏        | 34/300 [00:06<00:50,  5.29it/s]\n",
      "BPR:  12%|█▏        | 35/300 [00:06<00:50,  5.30it/s]\n",
      "BPR:  12%|█▏        | 36/300 [00:06<00:49,  5.32it/s]\n",
      "BPR:  12%|█▏        | 37/300 [00:07<00:49,  5.31it/s]\n",
      "BPR:  13%|█▎        | 38/300 [00:07<00:49,  5.27it/s]\n",
      "BPR:  13%|█▎        | 39/300 [00:07<00:49,  5.28it/s]\n",
      "BPR:  13%|█▎        | 40/300 [00:07<00:49,  5.29it/s]\n",
      "BPR:  14%|█▎        | 41/300 [00:07<00:49,  5.28it/s]\n",
      "BPR:  14%|█▍        | 42/300 [00:07<00:48,  5.28it/s]\n",
      "BPR:  14%|█▍        | 43/300 [00:08<00:48,  5.28it/s]\n",
      "BPR:  15%|█▍        | 44/300 [00:08<00:48,  5.30it/s]\n",
      "BPR:  15%|█▌        | 45/300 [00:08<00:48,  5.29it/s]\n",
      "BPR:  15%|█▌        | 46/300 [00:08<00:47,  5.30it/s]\n",
      "BPR:  16%|█▌        | 47/300 [00:08<00:47,  5.29it/s]\n",
      "BPR:  16%|█▌        | 48/300 [00:09<00:47,  5.27it/s]\n",
      "BPR:  16%|█▋        | 49/300 [00:09<00:47,  5.28it/s]\n",
      "BPR:  17%|█▋        | 50/300 [00:09<00:47,  5.29it/s]\n",
      "BPR:  17%|█▋        | 51/300 [00:09<00:47,  5.28it/s]\n",
      "BPR:  17%|█▋        | 52/300 [00:09<00:46,  5.28it/s]\n",
      "BPR:  18%|█▊        | 53/300 [00:10<00:47,  5.23it/s]\n",
      "BPR:  18%|█▊        | 54/300 [00:10<00:46,  5.24it/s]\n",
      "BPR:  18%|█▊        | 55/300 [00:10<00:46,  5.26it/s]\n",
      "BPR:  19%|█▊        | 56/300 [00:10<00:46,  5.27it/s]\n",
      "BPR:  19%|█▉        | 57/300 [00:10<00:46,  5.28it/s]\n",
      "BPR:  19%|█▉        | 58/300 [00:11<00:45,  5.28it/s]\n",
      "BPR:  20%|█▉        | 59/300 [00:11<00:46,  5.20it/s]\n",
      "BPR:  20%|██        | 60/300 [00:11<00:46,  5.21it/s]\n",
      "BPR:  20%|██        | 61/300 [00:11<00:45,  5.26it/s]\n",
      "BPR:  21%|██        | 62/300 [00:11<00:45,  5.28it/s]\n",
      "BPR:  21%|██        | 63/300 [00:11<00:44,  5.28it/s]\n",
      "BPR:  21%|██▏       | 64/300 [00:12<00:44,  5.30it/s]\n",
      "BPR:  22%|██▏       | 65/300 [00:12<00:44,  5.30it/s]\n",
      "BPR:  22%|██▏       | 66/300 [00:12<00:44,  5.30it/s]\n",
      "BPR:  22%|██▏       | 67/300 [00:12<00:43,  5.30it/s]\n",
      "BPR:  23%|██▎       | 68/300 [00:12<00:43,  5.29it/s]\n",
      "BPR:  23%|██▎       | 69/300 [00:13<00:43,  5.31it/s]\n",
      "BPR:  23%|██▎       | 70/300 [00:13<00:43,  5.31it/s]\n",
      "BPR:  24%|██▎       | 71/300 [00:13<00:43,  5.25it/s]\n",
      "BPR:  24%|██▍       | 72/300 [00:13<00:43,  5.27it/s]\n",
      "BPR:  24%|██▍       | 73/300 [00:13<00:42,  5.28it/s]\n",
      "BPR:  25%|██▍       | 74/300 [00:14<00:42,  5.28it/s]\n",
      "BPR:  25%|██▌       | 75/300 [00:14<00:42,  5.29it/s]\n",
      "BPR:  25%|██▌       | 76/300 [00:14<00:42,  5.30it/s]\n",
      "BPR:  26%|██▌       | 77/300 [00:14<00:42,  5.28it/s]\n",
      "BPR:  26%|██▌       | 78/300 [00:14<00:41,  5.29it/s]\n",
      "BPR:  26%|██▋       | 79/300 [00:14<00:41,  5.28it/s]\n",
      "BPR:  27%|██▋       | 80/300 [00:15<00:41,  5.28it/s]\n",
      "BPR:  27%|██▋       | 81/300 [00:15<00:42,  5.17it/s]\n",
      "BPR:  27%|██▋       | 82/300 [00:15<00:41,  5.22it/s]\n",
      "BPR:  28%|██▊       | 83/300 [00:15<00:41,  5.23it/s]\n",
      "BPR:  28%|██▊       | 84/300 [00:15<00:41,  5.25it/s]\n",
      "BPR:  28%|██▊       | 85/300 [00:16<00:40,  5.27it/s]\n",
      "BPR:  29%|██▊       | 86/300 [00:16<00:40,  5.26it/s]\n",
      "BPR:  29%|██▉       | 87/300 [00:16<00:40,  5.26it/s]\n",
      "BPR:  29%|██▉       | 88/300 [00:16<00:40,  5.26it/s]\n",
      "BPR:  30%|██▉       | 89/300 [00:16<00:39,  5.28it/s]\n",
      "BPR:  30%|███       | 90/300 [00:17<00:39,  5.30it/s]\n",
      "BPR:  30%|███       | 91/300 [00:17<00:39,  5.29it/s]\n",
      "BPR:  31%|███       | 92/300 [00:17<00:39,  5.30it/s]\n",
      "BPR:  31%|███       | 93/300 [00:17<00:39,  5.29it/s]\n",
      "BPR:  31%|███▏      | 94/300 [00:17<00:38,  5.29it/s]\n",
      "BPR:  32%|███▏      | 95/300 [00:18<00:38,  5.30it/s]\n",
      "BPR:  32%|███▏      | 96/300 [00:18<00:38,  5.29it/s]\n",
      "BPR:  32%|███▏      | 97/300 [00:18<00:38,  5.30it/s]\n",
      "BPR:  33%|███▎      | 98/300 [00:18<00:38,  5.29it/s]\n",
      "BPR:  33%|███▎      | 99/300 [00:18<00:38,  5.22it/s]\n",
      "BPR:  33%|███▎      | 100/300 [00:18<00:38,  5.23it/s]\n",
      "BPR:  34%|███▎      | 101/300 [00:19<00:37,  5.24it/s]\n",
      "BPR:  34%|███▍      | 102/300 [00:19<00:38,  5.18it/s]\n",
      "BPR:  34%|███▍      | 103/300 [00:19<00:38,  5.15it/s]\n",
      "BPR:  35%|███▍      | 104/300 [00:19<00:38,  5.14it/s]\n",
      "BPR:  35%|███▌      | 105/300 [00:19<00:37,  5.18it/s]\n",
      "BPR:  35%|███▌      | 106/300 [00:20<00:37,  5.19it/s]\n",
      "BPR:  36%|███▌      | 107/300 [00:20<00:37,  5.20it/s]\n",
      "BPR:  36%|███▌      | 108/300 [00:20<00:36,  5.24it/s]\n",
      "BPR:  36%|███▋      | 109/300 [00:20<00:36,  5.26it/s]\n",
      "BPR:  37%|███▋      | 110/300 [00:20<00:36,  5.23it/s]\n",
      "BPR:  37%|███▋      | 111/300 [00:21<00:36,  5.23it/s]\n",
      "BPR:  37%|███▋      | 112/300 [00:21<00:35,  5.24it/s]\n",
      "BPR:  38%|███▊      | 113/300 [00:21<00:35,  5.20it/s]\n",
      "BPR:  38%|███▊      | 114/300 [00:21<00:35,  5.20it/s]\n",
      "BPR:  38%|███▊      | 115/300 [00:21<00:35,  5.22it/s]\n",
      "BPR:  39%|███▊      | 116/300 [00:22<00:35,  5.23it/s]\n",
      "BPR:  39%|███▉      | 117/300 [00:22<00:35,  5.15it/s]\n",
      "BPR:  39%|███▉      | 118/300 [00:22<00:35,  5.17it/s]\n",
      "BPR:  40%|███▉      | 119/300 [00:22<00:34,  5.18it/s]\n",
      "BPR:  40%|████      | 120/300 [00:22<00:34,  5.21it/s]\n",
      "BPR:  40%|████      | 121/300 [00:23<00:34,  5.21it/s]\n",
      "BPR:  41%|████      | 122/300 [00:23<00:34,  5.22it/s]\n",
      "BPR:  41%|████      | 123/300 [00:23<00:33,  5.24it/s]\n",
      "BPR:  41%|████▏     | 124/300 [00:23<00:33,  5.24it/s]\n",
      "BPR:  42%|████▏     | 125/300 [00:23<00:33,  5.25it/s]\n",
      "BPR:  42%|████▏     | 126/300 [00:23<00:33,  5.25it/s]\n",
      "BPR:  42%|████▏     | 127/300 [00:24<00:32,  5.27it/s]\n",
      "BPR:  43%|████▎     | 128/300 [00:24<00:32,  5.26it/s]\n",
      "BPR:  43%|████▎     | 129/300 [00:24<00:32,  5.24it/s]\n",
      "BPR:  43%|████▎     | 130/300 [00:24<00:32,  5.22it/s]\n",
      "BPR:  44%|████▎     | 131/300 [00:24<00:32,  5.23it/s]\n",
      "BPR:  44%|████▍     | 132/300 [00:25<00:32,  5.24it/s]\n",
      "BPR:  44%|████▍     | 133/300 [00:25<00:31,  5.24it/s]\n",
      "BPR:  45%|████▍     | 134/300 [00:25<00:31,  5.20it/s]\n",
      "BPR:  45%|████▌     | 135/300 [00:25<00:31,  5.21it/s]\n",
      "BPR:  45%|████▌     | 136/300 [00:25<00:31,  5.23it/s]\n",
      "BPR:  46%|████▌     | 137/300 [00:26<00:31,  5.25it/s]\n",
      "BPR:  46%|████▌     | 138/300 [00:26<00:30,  5.25it/s]\n",
      "BPR:  46%|████▋     | 139/300 [00:26<00:30,  5.26it/s]\n",
      "BPR:  47%|████▋     | 140/300 [00:26<00:30,  5.27it/s]\n",
      "BPR:  47%|████▋     | 141/300 [00:26<00:30,  5.27it/s]\n",
      "BPR:  47%|████▋     | 142/300 [00:27<00:29,  5.27it/s]\n",
      "BPR:  48%|████▊     | 143/300 [00:27<00:29,  5.27it/s]\n",
      "BPR:  48%|████▊     | 144/300 [00:27<00:29,  5.28it/s]\n",
      "BPR:  48%|████▊     | 145/300 [00:27<00:29,  5.27it/s]\n",
      "BPR:  49%|████▊     | 146/300 [00:27<00:29,  5.27it/s]\n",
      "BPR:  49%|████▉     | 147/300 [00:27<00:28,  5.28it/s]\n",
      "BPR:  49%|████▉     | 148/300 [00:28<00:28,  5.26it/s]\n",
      "BPR:  50%|████▉     | 149/300 [00:28<00:28,  5.24it/s]\n",
      "BPR:  50%|█████     | 150/300 [00:28<00:28,  5.21it/s]\n",
      "BPR:  50%|█████     | 151/300 [00:28<00:28,  5.22it/s]\n",
      "BPR:  51%|█████     | 152/300 [00:28<00:28,  5.23it/s]\n",
      "BPR:  51%|█████     | 153/300 [00:29<00:27,  5.26it/s]\n",
      "BPR:  51%|█████▏    | 154/300 [00:29<00:27,  5.26it/s]\n",
      "BPR:  52%|█████▏    | 155/300 [00:29<00:27,  5.23it/s]\n",
      "BPR:  52%|█████▏    | 156/300 [00:29<00:27,  5.25it/s]\n",
      "BPR:  52%|█████▏    | 157/300 [00:29<00:27,  5.25it/s]\n",
      "BPR:  53%|█████▎    | 158/300 [00:30<00:27,  5.23it/s]\n",
      "BPR:  53%|█████▎    | 159/300 [00:30<00:27,  5.19it/s]\n",
      "BPR:  53%|█████▎    | 160/300 [00:30<00:27,  5.14it/s]\n",
      "BPR:  54%|█████▎    | 161/300 [00:30<00:26,  5.18it/s]\n",
      "BPR:  54%|█████▍    | 162/300 [00:30<00:26,  5.22it/s]\n",
      "BPR:  54%|█████▍    | 163/300 [00:31<00:26,  5.23it/s]\n",
      "BPR:  55%|█████▍    | 164/300 [00:31<00:26,  5.20it/s]\n",
      "BPR:  55%|█████▌    | 165/300 [00:31<00:25,  5.20it/s]\n",
      "BPR:  55%|█████▌    | 166/300 [00:31<00:25,  5.22it/s]\n",
      "BPR:  56%|█████▌    | 167/300 [00:31<00:25,  5.25it/s]\n",
      "BPR:  56%|█████▌    | 168/300 [00:31<00:25,  5.25it/s]\n",
      "BPR:  56%|█████▋    | 169/300 [00:32<00:24,  5.25it/s]\n",
      "BPR:  57%|█████▋    | 170/300 [00:32<00:24,  5.27it/s]\n",
      "BPR:  57%|█████▋    | 171/300 [00:32<00:24,  5.27it/s]\n",
      "BPR:  57%|█████▋    | 172/300 [00:32<00:24,  5.27it/s]\n",
      "BPR:  58%|█████▊    | 173/300 [00:32<00:24,  5.28it/s]\n",
      "BPR:  58%|█████▊    | 174/300 [00:33<00:23,  5.29it/s]\n",
      "BPR:  58%|█████▊    | 175/300 [00:33<00:23,  5.28it/s]\n",
      "BPR:  59%|█████▊    | 176/300 [00:33<00:23,  5.28it/s]\n",
      "BPR:  59%|█████▉    | 177/300 [00:33<00:23,  5.28it/s]\n",
      "BPR:  59%|█████▉    | 178/300 [00:33<00:23,  5.29it/s]\n",
      "BPR:  60%|█████▉    | 179/300 [00:34<00:22,  5.28it/s]\n",
      "BPR:  60%|██████    | 180/300 [00:34<00:22,  5.30it/s]\n",
      "BPR:  60%|██████    | 181/300 [00:34<00:22,  5.30it/s]\n",
      "BPR:  61%|██████    | 182/300 [00:34<00:22,  5.16it/s]\n",
      "BPR:  61%|██████    | 183/300 [00:34<00:22,  5.15it/s]\n",
      "BPR:  61%|██████▏   | 184/300 [00:35<00:22,  5.19it/s]\n",
      "BPR:  62%|██████▏   | 185/300 [00:35<00:22,  5.19it/s]\n",
      "BPR:  62%|██████▏   | 186/300 [00:35<00:21,  5.19it/s]\n",
      "BPR:  62%|██████▏   | 187/300 [00:35<00:21,  5.17it/s]\n",
      "BPR:  63%|██████▎   | 188/300 [00:35<00:21,  5.18it/s]\n",
      "BPR:  63%|██████▎   | 189/300 [00:36<00:21,  5.16it/s]\n",
      "BPR:  63%|██████▎   | 190/300 [00:36<00:21,  5.15it/s]\n",
      "BPR:  64%|██████▎   | 191/300 [00:36<00:21,  5.19it/s]\n",
      "BPR:  64%|██████▍   | 192/300 [00:36<00:20,  5.21it/s]\n",
      "BPR:  64%|██████▍   | 193/300 [00:36<00:20,  5.23it/s]\n",
      "BPR:  65%|██████▍   | 194/300 [00:36<00:20,  5.21it/s]\n",
      "BPR:  65%|██████▌   | 195/300 [00:37<00:20,  5.11it/s]\n",
      "BPR:  65%|██████▌   | 196/300 [00:37<00:20,  5.13it/s]\n",
      "BPR:  66%|██████▌   | 197/300 [00:37<00:19,  5.17it/s]\n",
      "BPR:  66%|██████▌   | 198/300 [00:37<00:19,  5.20it/s]\n",
      "BPR:  66%|██████▋   | 199/300 [00:37<00:19,  5.23it/s]\n",
      "BPR:  67%|██████▋   | 200/300 [00:38<00:19,  5.24it/s]\n",
      "BPR:  67%|██████▋   | 201/300 [00:38<00:18,  5.24it/s]\n",
      "BPR:  67%|██████▋   | 202/300 [00:38<00:18,  5.27it/s]\n",
      "BPR:  68%|██████▊   | 203/300 [00:38<00:18,  5.27it/s]\n",
      "BPR:  68%|██████▊   | 204/300 [00:38<00:18,  5.19it/s]\n",
      "BPR:  68%|██████▊   | 205/300 [00:39<00:18,  5.23it/s]\n",
      "BPR:  69%|██████▊   | 206/300 [00:39<00:18,  5.20it/s]\n",
      "BPR:  69%|██████▉   | 207/300 [00:39<00:17,  5.22it/s]\n",
      "BPR:  69%|██████▉   | 208/300 [00:39<00:17,  5.26it/s]\n",
      "BPR:  70%|██████▉   | 209/300 [00:39<00:17,  5.23it/s]\n",
      "BPR:  70%|███████   | 210/300 [00:40<00:17,  5.25it/s]\n",
      "BPR:  70%|███████   | 211/300 [00:40<00:16,  5.25it/s]\n",
      "BPR:  71%|███████   | 212/300 [00:40<00:16,  5.26it/s]\n",
      "BPR:  71%|███████   | 213/300 [00:40<00:16,  5.23it/s]\n",
      "BPR:  71%|███████▏  | 214/300 [00:40<00:16,  5.23it/s]\n",
      "BPR:  72%|███████▏  | 215/300 [00:40<00:16,  5.26it/s]\n",
      "BPR:  72%|███████▏  | 216/300 [00:41<00:16,  5.25it/s]\n",
      "BPR:  72%|███████▏  | 217/300 [00:41<00:15,  5.25it/s]\n",
      "BPR:  73%|███████▎  | 218/300 [00:41<00:15,  5.24it/s]\n",
      "BPR:  73%|███████▎  | 219/300 [00:41<00:15,  5.15it/s]\n",
      "BPR:  73%|███████▎  | 220/300 [00:41<00:15,  5.19it/s]\n",
      "BPR:  74%|███████▎  | 221/300 [00:42<00:15,  5.20it/s]\n",
      "BPR:  74%|███████▍  | 222/300 [00:42<00:14,  5.22it/s]\n",
      "BPR:  74%|███████▍  | 223/300 [00:42<00:14,  5.24it/s]\n",
      "BPR:  75%|███████▍  | 224/300 [00:42<00:14,  5.22it/s]\n",
      "BPR:  75%|███████▌  | 225/300 [00:42<00:14,  5.22it/s]\n",
      "BPR:  75%|███████▌  | 226/300 [00:43<00:14,  5.25it/s]\n",
      "BPR:  76%|███████▌  | 227/300 [00:43<00:13,  5.27it/s]\n",
      "BPR:  76%|███████▌  | 228/300 [00:43<00:13,  5.27it/s]\n",
      "BPR:  76%|███████▋  | 229/300 [00:43<00:13,  5.26it/s]\n",
      "BPR:  77%|███████▋  | 230/300 [00:43<00:13,  5.25it/s]\n",
      "BPR:  77%|███████▋  | 231/300 [00:44<00:13,  5.26it/s]\n",
      "BPR:  77%|███████▋  | 232/300 [00:44<00:12,  5.26it/s]\n",
      "BPR:  78%|███████▊  | 233/300 [00:44<00:12,  5.24it/s]\n",
      "BPR:  78%|███████▊  | 234/300 [00:44<00:12,  5.26it/s]\n",
      "BPR:  78%|███████▊  | 235/300 [00:44<00:12,  5.26it/s]\n",
      "BPR:  79%|███████▊  | 236/300 [00:44<00:12,  5.25it/s]\n",
      "BPR:  79%|███████▉  | 237/300 [00:45<00:12,  5.24it/s]\n",
      "BPR:  79%|███████▉  | 238/300 [00:45<00:12,  5.14it/s]\n",
      "BPR:  80%|███████▉  | 239/300 [00:45<00:11,  5.17it/s]\n",
      "BPR:  80%|████████  | 240/300 [00:45<00:11,  5.17it/s]\n",
      "BPR:  80%|████████  | 241/300 [00:45<00:11,  5.20it/s]\n",
      "BPR:  81%|████████  | 242/300 [00:46<00:11,  5.22it/s]\n",
      "BPR:  81%|████████  | 243/300 [00:46<00:10,  5.22it/s]\n",
      "BPR:  81%|████████▏ | 244/300 [00:46<00:10,  5.25it/s]\n",
      "BPR:  82%|████████▏ | 245/300 [00:46<00:10,  5.26it/s]\n",
      "BPR:  82%|████████▏ | 246/300 [00:46<00:10,  5.26it/s]\n",
      "BPR:  82%|████████▏ | 247/300 [00:47<00:10,  5.19it/s]\n",
      "BPR:  83%|████████▎ | 248/300 [00:47<00:09,  5.22it/s]\n",
      "BPR:  83%|████████▎ | 249/300 [00:47<00:09,  5.25it/s]\n",
      "BPR:  83%|████████▎ | 250/300 [00:47<00:09,  5.26it/s]\n",
      "BPR:  84%|████████▎ | 251/300 [00:47<00:09,  5.27it/s]\n",
      "BPR:  84%|████████▍ | 252/300 [00:48<00:09,  5.25it/s]\n",
      "BPR:  84%|████████▍ | 253/300 [00:48<00:08,  5.24it/s]\n",
      "BPR:  85%|████████▍ | 254/300 [00:48<00:08,  5.24it/s]\n",
      "BPR:  85%|████████▌ | 255/300 [00:48<00:08,  5.24it/s]\n",
      "BPR:  85%|████████▌ | 256/300 [00:48<00:08,  5.17it/s]\n",
      "BPR:  86%|████████▌ | 257/300 [00:49<00:08,  5.21it/s]\n",
      "BPR:  86%|████████▌ | 258/300 [00:49<00:08,  5.23it/s]\n",
      "BPR:  86%|████████▋ | 259/300 [00:49<00:07,  5.23it/s]\n",
      "BPR:  87%|████████▋ | 260/300 [00:49<00:07,  5.24it/s]\n",
      "BPR:  87%|████████▋ | 261/300 [00:49<00:07,  5.27it/s]\n",
      "BPR:  87%|████████▋ | 262/300 [00:49<00:07,  5.26it/s]\n",
      "BPR:  88%|████████▊ | 263/300 [00:50<00:07,  5.25it/s]\n",
      "BPR:  88%|████████▊ | 264/300 [00:50<00:06,  5.23it/s]\n",
      "BPR:  88%|████████▊ | 265/300 [00:50<00:06,  5.25it/s]\n",
      "BPR:  89%|████████▊ | 266/300 [00:50<00:06,  5.27it/s]\n",
      "BPR:  89%|████████▉ | 267/300 [00:50<00:06,  5.13it/s]\n",
      "BPR:  89%|████████▉ | 268/300 [00:51<00:06,  5.16it/s]\n",
      "BPR:  90%|████████▉ | 269/300 [00:51<00:05,  5.18it/s]\n",
      "BPR:  90%|█████████ | 270/300 [00:51<00:05,  5.13it/s]\n",
      "BPR:  90%|█████████ | 271/300 [00:51<00:05,  4.96it/s]\n",
      "BPR:  91%|█████████ | 272/300 [00:51<00:05,  5.04it/s]\n",
      "BPR:  91%|█████████ | 273/300 [00:52<00:05,  5.00it/s]\n",
      "BPR:  91%|█████████▏| 274/300 [00:52<00:05,  5.07it/s]\n",
      "BPR:  92%|█████████▏| 275/300 [00:52<00:04,  5.11it/s]\n",
      "BPR:  92%|█████████▏| 276/300 [00:52<00:04,  5.17it/s]\n",
      "BPR:  92%|█████████▏| 277/300 [00:52<00:04,  5.20it/s]\n",
      "BPR:  93%|█████████▎| 278/300 [00:53<00:04,  5.23it/s]\n",
      "BPR:  93%|█████████▎| 279/300 [00:53<00:04,  5.24it/s]\n",
      "BPR:  93%|█████████▎| 280/300 [00:53<00:03,  5.23it/s]\n",
      "BPR:  94%|█████████▎| 281/300 [00:53<00:03,  5.27it/s]\n",
      "BPR:  94%|█████████▍| 282/300 [00:53<00:03,  5.27it/s]\n",
      "BPR:  94%|█████████▍| 283/300 [00:54<00:03,  5.25it/s]\n",
      "BPR:  95%|█████████▍| 284/300 [00:54<00:03,  5.25it/s]\n",
      "BPR:  95%|█████████▌| 285/300 [00:54<00:02,  5.25it/s]\n",
      "BPR:  95%|█████████▌| 286/300 [00:54<00:02,  5.26it/s]\n",
      "BPR:  96%|█████████▌| 287/300 [00:54<00:02,  5.27it/s]\n",
      "BPR:  96%|█████████▌| 288/300 [00:54<00:02,  5.26it/s]\n",
      "BPR:  96%|█████████▋| 289/300 [00:55<00:02,  5.20it/s]\n",
      "BPR:  97%|█████████▋| 290/300 [00:55<00:01,  5.17it/s]\n",
      "BPR:  97%|█████████▋| 291/300 [00:55<00:01,  5.14it/s]\n",
      "BPR:  97%|█████████▋| 292/300 [00:55<00:01,  5.15it/s]\n",
      "BPR:  98%|█████████▊| 293/300 [00:55<00:01,  5.19it/s]\n",
      "BPR:  98%|█████████▊| 294/300 [00:56<00:01,  5.21it/s]\n",
      "BPR:  98%|█████████▊| 295/300 [00:56<00:00,  5.16it/s]\n",
      "BPR:  99%|█████████▊| 296/300 [00:56<00:00,  5.17it/s]\n",
      "BPR:  99%|█████████▉| 297/300 [00:56<00:00,  5.16it/s]\n",
      "BPR:  99%|█████████▉| 298/300 [00:56<00:00,  5.03it/s]\n",
      "BPR: 100%|█████████▉| 299/300 [00:57<00:00,  5.06it/s]\n",
      "BPR: 100%|██████████| 300/300 [00:57<00:00,  5.11it/s]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.BPR at 0x168ea3ca390>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parameters were randomly chosen\n",
    "bpr_params = {'reg': 0.01,\n",
    "              'learning_rate': 0.05,\n",
    "              'n_iters': 300,\n",
    "              'n_factors': 20,\n",
    "              'batch_size': 100}\n",
    "\n",
    "bpr = BPR(**bpr_params)\n",
    "bpr.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation through AUC\n",
    "def auc_score(model, ratings):\n",
    "    auc = 0.0\n",
    "    n_users, n_items = ratings.shape\n",
    "    for user, row in enumerate(ratings):\n",
    "        y_pred = model._predict_user(user)\n",
    "        y_true = np.zeros(n_items)\n",
    "        y_true[row.indices] = 1\n",
    "        auc += roc_auc_score(y_true, y_pred)\n",
    "\n",
    "    auc /= n_users\n",
    "    return auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9528987879486526\n"
     ]
    }
   ],
   "source": [
    "print(auc_score(bpr, X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8085029940408277\n"
     ]
    }
   ],
   "source": [
    "print(auc_score(bpr, X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  5,  19],\n",
       "       [ 74,  73],\n",
       "       [ 37,  81],\n",
       "       [ 25,  21],\n",
       "       [ 39,  59],\n",
       "       [ 67,  10],\n",
       "       [100,  87],\n",
       "       [ 59,  32],\n",
       "       [ 54,  38],\n",
       "       [  5,  10],\n",
       "       [  5,  96],\n",
       "       [ 77,  51],\n",
       "       [ 46,  60],\n",
       "       [ 52,  77],\n",
       "       [ 35,  98],\n",
       "       [ 43,  55],\n",
       "       [ 44,  15],\n",
       "       [ 39,  52],\n",
       "       [ 55,  52],\n",
       "       [ 76,  53],\n",
       "       [ 74,  68],\n",
       "       [ 16,  44],\n",
       "       [ 57,  82],\n",
       "       [ 53,  99],\n",
       "       [ 37,  82],\n",
       "       [  7,  10],\n",
       "       [ 96,   8],\n",
       "       [ 36,  62],\n",
       "       [ 53,  42],\n",
       "       [102,  64],\n",
       "       [ 59,  13],\n",
       "       [ 33,   8],\n",
       "       [  7,  55],\n",
       "       [ 54,  91],\n",
       "       [ 96,  51],\n",
       "       [ 98,  77],\n",
       "       [ 27,   4],\n",
       "       [ 81,  24],\n",
       "       [ 12,  46],\n",
       "       [ 52,  98],\n",
       "       [ 64,  52],\n",
       "       [ 39,  63],\n",
       "       [ 80,  28],\n",
       "       [ 15,  18],\n",
       "       [ 16,  15],\n",
       "       [ 75,  79],\n",
       "       [ 12,  60],\n",
       "       [ 79,  34],\n",
       "       [ 84,  40],\n",
       "       [ 66,  61],\n",
       "       [ 29,  39],\n",
       "       [ 46,  77],\n",
       "       [ 64,  13],\n",
       "       [ 11,  12],\n",
       "       [ 35,  60],\n",
       "       [ 18,  77],\n",
       "       [ 44,  42],\n",
       "       [ 77,  13],\n",
       "       [ 74,  14],\n",
       "       [ 52,  30],\n",
       "       [ 12,  46],\n",
       "       [ 49,  19],\n",
       "       [ 13,  18],\n",
       "       [ 68, 102],\n",
       "       [ 52,  77],\n",
       "       [ 62,  37],\n",
       "       [ 98,  11],\n",
       "       [  5,  32],\n",
       "       [ 46,  12],\n",
       "       [ 58,  98],\n",
       "       [  8,  31],\n",
       "       [  8,  88],\n",
       "       [ 14,  84],\n",
       "       [ 43,  16],\n",
       "       [ 38,  98],\n",
       "       [ 84,  45],\n",
       "       [ 88,  12],\n",
       "       [ 64,  60],\n",
       "       [ 45,  71],\n",
       "       [ 47,  45],\n",
       "       [ 32,  54],\n",
       "       [ 37,  24],\n",
       "       [ 24,  37],\n",
       "       [ 76,  88],\n",
       "       [ 98,  46],\n",
       "       [ 62,  13],\n",
       "       [ 19,  53],\n",
       "       [ 88,   4],\n",
       "       [ 30,  39],\n",
       "       [ 48,  54],\n",
       "       [ 32,  96],\n",
       "       [ 52,  59],\n",
       "       [ 62,  43],\n",
       "       [ 80,  74],\n",
       "       [ 64,  11],\n",
       "       [ 16,  62],\n",
       "       [ 77,  51],\n",
       "       [ 24,  31],\n",
       "       [ 35,  11],\n",
       "       [ 11,  55],\n",
       "       [ 35,  12],\n",
       "       [ 91,  40],\n",
       "       [ 46,  38]], dtype=uint32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpr.get_similar_items(N = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[31, 70],\n",
       "       [65, 92],\n",
       "       [22, 24],\n",
       "       ...,\n",
       "       [71, 31],\n",
       "       [47, 65],\n",
       "       [65, 24]], dtype=uint32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpr.recommend(X_train, N = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation through ROC\n",
    "def auc_score(model, ratings):\n",
    "    auc = 0.0\n",
    "    n_users, n_items = ratings.shape\n",
    "    for user, row in enumerate(ratings):\n",
    "        y_pred = model._predict_user(user)\n",
    "        y_true = np.zeros(n_items)\n",
    "        y_true[row.indices] = 1\n",
    "        auc += roc_auc_score(y_true, y_pred)\n",
    "\n",
    "    auc /= n_users\n",
    "    return auc\n",
    "    return y_pred\n",
    "    return y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8085029940408277\n"
     ]
    }
   ],
   "source": [
    "print(auc_score(bpr, X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
